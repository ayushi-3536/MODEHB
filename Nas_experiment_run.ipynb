{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nas_experiment_run.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDS3nYP847vRxH7QiK6j/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushi-3536/MODEHB/blob/testing/Nas_experiment_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gokzmi5U7Uzh"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPFYsq7E7Zx2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',\n",
        " force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG5L86DL87Oo"
      },
      "source": [
        "!tar xvf '/content/drive/MyDrive/NATS-tss-v1_0-3ffb9-simple.tar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkFimFKw7idv"
      },
      "source": [
        "from functools import partial\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class temporary_seed:\n",
        "    def __init__(self, seed):\n",
        "        self.seed = seed\n",
        "        self.backup = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.backup = np.random.randint(2 ** 32 - 1, dtype=np.uint32)\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "    def __exit__(self, *_):\n",
        "        np.random.seed(self.backup)\n",
        "\n",
        "\n",
        "class GaussianTransform:\n",
        "    \"\"\"\n",
        "    Transform data into Gaussian by applying psi = Phi^{-1} o F where F is the truncated ECDF.\n",
        "    :param y: shape (n, dim)\n",
        "    :param randomize_identical: whether to randomize the rank when consecutive values exists\n",
        "    if True, draw uniformly inbetween extreme values, if False, use lowest value\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, y: np.array, randomize_identical: bool = True):\n",
        "        assert y.ndim == 2\n",
        "        self.dim = y.shape[1]\n",
        "        self.sorted = y.copy()\n",
        "        self.sorted.sort(axis=0)\n",
        "        self.randomize_identical = randomize_identical\n",
        "\n",
        "    @staticmethod\n",
        "    def z_transform(series, values_sorted=None, randomize_identical: bool = True):\n",
        "        # in case of multiple occurences we sample in the interval to get uniform distribution with PIT\n",
        "        # to obtain deterministic results, we fix the seed locally (and restore the global seed after)\n",
        "        with temporary_seed(40):\n",
        "            # applies truncated ECDF then inverse Gaussian CDF.\n",
        "            if values_sorted is None:\n",
        "                assert False\n",
        "                values_sorted = sorted(series)\n",
        "\n",
        "            def winsorized_delta(n):\n",
        "                return 1.0 / (4.0 * n ** 0.25 * np.sqrt(np.pi * np.log(n)))\n",
        "\n",
        "            # delta = winsorized_delta(len(series))\n",
        "            delta = winsorized_delta(len(values_sorted))\n",
        "\n",
        "            def quantile(values_sorted, values_to_insert, delta):\n",
        "                # in case where multiple occurences of the same value exists in sorted array\n",
        "                # we return a random index in the valid range\n",
        "                low = np.searchsorted(values_sorted, values_to_insert, side='left')\n",
        "                if not randomize_identical:\n",
        "                    res = low\n",
        "                else:\n",
        "                    high = np.searchsorted(values_sorted, values_to_insert, side='right')\n",
        "                    res = np.random.randint(low, np.maximum(high, low + 1))\n",
        "                return np.clip(res / len(values_sorted), a_min=delta, a_max=1 - delta)\n",
        "\n",
        "            quantiles = quantile(\n",
        "                values_sorted,\n",
        "                series,\n",
        "                delta\n",
        "            )\n",
        "\n",
        "            quantiles = np.clip(quantiles, a_min=delta, a_max=1 - delta)\n",
        "            # We want 0-1 transforms\n",
        "            return quantiles\n",
        "            # return stats.norm.ppf(quantiles)\n",
        "\n",
        "    def transform(self, y: np.array):\n",
        "        \"\"\"\n",
        "        :param y: shape (n, dim)\n",
        "        :return: shape (n, dim), distributed along a normal\n",
        "        \"\"\"\n",
        "        assert y.shape[1] == self.dim\n",
        "        # compute truncated quantile, apply gaussian inv cdf\n",
        "        return np.stack([\n",
        "            self.z_transform(y[:, i], self.sorted[:, i], self.randomize_identical)\n",
        "            for i in range(self.dim)\n",
        "        ]).T\n",
        "\n",
        "\n",
        "class StandardTransform:\n",
        "\n",
        "    def __init__(self, y: np.array):\n",
        "        assert y.ndim == 2\n",
        "        self.dim = y.shape[1]\n",
        "        self.mean = y.mean(axis=0, keepdims=True)\n",
        "        self.std = y.std(axis=0, keepdims=True)\n",
        "\n",
        "    def transform(self, y: np.array):\n",
        "        z = (y - self.mean) / np.clip(self.std, a_min=0.001, a_max=None)\n",
        "        return z\n",
        "\n",
        "\n",
        "def from_string(name: str, randomize_identical: bool):\n",
        "    assert name in [\"standard\", \"gaussian\"]\n",
        "    mapping = {\n",
        "        \"standard\": StandardTransform,\n",
        "        \"gaussian\": partial(GaussianTransform, randomize_identical=randomize_identical),\n",
        "    }\n",
        "    return mapping[name]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n = 1000\n",
        "    tol = 0.05\n",
        "    dim = 2\n",
        "    y = np.random.uniform(size=(n, dim))\n",
        "    #print(y)\n",
        "    %matplotlib inline\n",
        "    import numpy as np\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "    cost = np.loadtxt(\"/content/drive/MyDrive/run/changedk/imagenet16/32_runtime_b199/_1/every_run_cost_1634500997.1196012.txt\")\n",
        "    #cost = np.loadtxt(\"/content/drive/MyDrive/run/imagenet16/optimalhvimprov20011/optimal_metric_pertime.txt\")\n",
        "    #print(cost)\n",
        "    y=np.array(cost)\n",
        "    # print(\"cost shape:{}, n dim:{}\",y.shape,y.ndim)\n",
        "    # # GaussianTransform, StandardTransform\n",
        "    psi = GaussianTransform(y)\n",
        "    print(psi)\n",
        "    #print(\"cost transform shape:{}\",psi.shape)\n",
        "    z = psi.transform(y)\n",
        "    # front = pareto(z)\n",
        "    # print(front)\n",
        "    # zp= z[front, :]\n",
        "    # print(\"z is done for cost\")\n",
        "    #zp = np.loadtxt(\"/content/drive/MyDrive/run/imagenet16/optimalhvimprov20011/pareto_pertime.txt\")\n",
        "    # print(\"pareto shape:\",p1.shape)\n",
        "    # print(\"pareto array shape:\",np.array(p1).shape)\n",
        "    # print(\"cost:{}, pareto:{}\",cost.ndim,p1.ndim)\n",
        "    # psi_p = GaussianTransform(p1)\n",
        "    # #print(\"p dim:{}\",psi.ndim)\n",
        "    # #print(\"psi shape:{}\",psi_p.ndim)\n",
        "    # zp = psi_p.transform(p1)\n",
        "    print(zp)\n",
        "    plt.scatter(z[:, 0], z[:, 1],color='green', marker='o',label=\"sampled_config\")\n",
        "    plt.scatter(zp[:, 0], zp[:, 1],color='blue', marker='o',label=\"pareto\")\n",
        "\n",
        "    plt.title('MODEHB Pareto Front: Cifar-10, runtime=24h, hp=200')\n",
        "    plt.xlabel('validation-acc')\n",
        "    plt.ylabel('model_param')\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/run/imagenet16/optimalhvimprov20011/pareto_normalized.txt\", 'w') as f:\n",
        "          np.savetxt(f,zp)\n",
        "\n",
        "\n",
        "    # assert np.allclose(z.mean(axis=0), np.zeros((dim,)), rtol=tol, atol=tol)\n",
        "    # assert np.allclose(z.std(axis=0), np.ones((dim,)), rtol=tol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNIYNJkA8y4i"
      },
      "source": [
        "from functools import partial\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class temporary_seed:\n",
        "    def __init__(self, seed):\n",
        "        self.seed = seed\n",
        "        self.backup = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.backup = np.random.randint(2 ** 32 - 1, dtype=np.uint32)\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "    def __exit__(self, *_):\n",
        "        np.random.seed(self.backup)\n",
        "\n",
        "\n",
        "class GaussianTransform:\n",
        "    \"\"\"\n",
        "    Transform data into Gaussian by applying psi = Phi^{-1} o F where F is the truncated ECDF.\n",
        "    :param y: shape (n, dim)\n",
        "    :param randomize_identical: whether to randomize the rank when consecutive values exists\n",
        "    if True, draw uniformly inbetween extreme values, if False, use lowest value\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, y: np.array, randomize_identical: bool = True):\n",
        "        assert y.ndim == 2\n",
        "        self.dim = y.shape[1]\n",
        "        self.sorted = y.copy()\n",
        "        self.sorted.sort(axis=0)\n",
        "        self.randomize_identical = randomize_identical\n",
        "\n",
        "    @staticmethod\n",
        "    def z_transform(series, values_sorted=None, randomize_identical: bool = True):\n",
        "        # in case of multiple occurences we sample in the interval to get uniform distribution with PIT\n",
        "        # to obtain deterministic results, we fix the seed locally (and restore the global seed after)\n",
        "        with temporary_seed(40):\n",
        "            # applies truncated ECDF then inverse Gaussian CDF.\n",
        "            if values_sorted is None:\n",
        "                assert False\n",
        "                values_sorted = sorted(series)\n",
        "\n",
        "            def winsorized_delta(n):\n",
        "                return 1.0 / (4.0 * n ** 0.25 * np.sqrt(np.pi * np.log(n)))\n",
        "\n",
        "            # delta = winsorized_delta(len(series))\n",
        "            delta = winsorized_delta(len(values_sorted))\n",
        "\n",
        "            def quantile(values_sorted, values_to_insert, delta):\n",
        "                # in case where multiple occurences of the same value exists in sorted array\n",
        "                # we return a random index in the valid range\n",
        "                low = np.searchsorted(values_sorted, values_to_insert, side='left')\n",
        "                if not randomize_identical:\n",
        "                    res = low\n",
        "                else:\n",
        "                    high = np.searchsorted(values_sorted, values_to_insert, side='right')\n",
        "                    res = np.random.randint(low, np.maximum(high, low + 1))\n",
        "                return np.clip(res / len(values_sorted), a_min=delta, a_max=1 - delta)\n",
        "\n",
        "            quantiles = quantile(\n",
        "                values_sorted,\n",
        "                series,\n",
        "                delta\n",
        "            )\n",
        "\n",
        "            quantiles = np.clip(quantiles, a_min=delta, a_max=1 - delta)\n",
        "            # We want 0-1 transforms\n",
        "            return quantiles\n",
        "            # return stats.norm.ppf(quantiles)\n",
        "\n",
        "    def transform(self, y: np.array):\n",
        "        \"\"\"\n",
        "        :param y: shape (n, dim)\n",
        "        :return: shape (n, dim), distributed along a normal\n",
        "        \"\"\"\n",
        "        assert y.shape[1] == self.dim\n",
        "        # compute truncated quantile, apply gaussian inv cdf\n",
        "        return np.stack([\n",
        "            self.z_transform(y[:, i], self.sorted[:, i], self.randomize_identical)\n",
        "            for i in range(self.dim)\n",
        "        ]).T\n",
        "\n",
        "\n",
        "class StandardTransform:\n",
        "\n",
        "    def __init__(self, y: np.array):\n",
        "        assert y.ndim == 2\n",
        "        self.dim = y.shape[1]\n",
        "        self.mean = y.mean(axis=0, keepdims=True)\n",
        "        self.std = y.std(axis=0, keepdims=True)\n",
        "\n",
        "    def transform(self, y: np.array):\n",
        "        z = (y - self.mean) / np.clip(self.std, a_min=0.001, a_max=None)\n",
        "        return z\n",
        "\n",
        "\n",
        "def from_string(name: str, randomize_identical: bool):\n",
        "    assert name in [\"standard\", \"gaussian\"]\n",
        "    mapping = {\n",
        "        \"standard\": StandardTransform,\n",
        "        \"gaussian\": partial(GaussianTransform, randomize_identical=randomize_identical),\n",
        "    }\n",
        "    return mapping[name]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n = 1000\n",
        "    tol = 0.05\n",
        "    dim = 2\n",
        "    y = np.random.uniform(size=(n, dim))\n",
        "    #print(y)\n",
        "    %matplotlib inline\n",
        "    import numpy as np\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "    #cost = np.loadtxt(\"/content/drive/MyDrive/run/changedk/imagenet16/32_runtime_b199/_1/every_run_cost_1634500997.1196012.txt\")\n",
        "    cost = np.loadtxt(\"/content/drive/MyDrive/run/imagenet16/optimalhvimprov20011/optimal_metric_pertime.txt\")\n",
        "    #print(cost)\n",
        "    y=np.array(cost)\n",
        "    print(\"cost shape:{}, n dim:{}\",y.shape,y.ndim)\n",
        "    # GaussianTransform, StandardTransform\n",
        "    psi = GaussianTransform(y)\n",
        "    print(psi)\n",
        "    #print(\"cost transform shape:{}\",psi.shape)\n",
        "    z = psi.transform(y)\n",
        "    front = pareto(z)\n",
        "    print(front)\n",
        "    zp= z[front, :]\n",
        "    print(\"z is done for cost\")\n",
        "    #zp = np.loadtxt(\"/content/drive/MyDrive/run/imagenet16/optimalhvimprov20011/pareto_pertime.txt\")\n",
        "    # print(\"pareto shape:\",p1.shape)\n",
        "    # print(\"pareto array shape:\",np.array(p1).shape)\n",
        "    # print(\"cost:{}, pareto:{}\",cost.ndim,p1.ndim)\n",
        "    # psi_p = GaussianTransform(p1)\n",
        "    # #print(\"p dim:{}\",psi.ndim)\n",
        "    # #print(\"psi shape:{}\",psi_p.ndim)\n",
        "    # zp = psi_p.transform(p1)\n",
        "    print(zp)\n",
        "    plt.scatter(z[:, 0], z[:, 1],color='green', marker='o',label=\"sampled_config\")\n",
        "    plt.scatter(zp[:, 0], zp[:, 1],color='blue', marker='o',label=\"pareto\")\n",
        "\n",
        "    plt.title('MODEHB Pareto Front: Cifar-10, runtime=24h, hp=200')\n",
        "    plt.xlabel('validation-acc')\n",
        "    plt.ylabel('model_param')\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/run/imagenet16/optimalhvimprov20011/pareto_normalized.txt\", 'w') as f:\n",
        "          np.savetxt(f,zp)\n",
        "\n",
        "\n",
        "    # assert np.allclose(z.mean(axis=0), np.zeros((dim,)), rtol=tol, atol=tol)\n",
        "    # assert np.allclose(z.std(axis=0), np.ones((dim,)), rtol=tol)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}